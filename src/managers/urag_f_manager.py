# -*- coding: utf-8 -*-
"""
FManager â€” FAQ pipeline orchestrator
===================================

Chá»©c nÄƒng Ä‘Ãºng theo yÃªu cáº§u:
1) augmentedChunks tÃ i liá»‡u -> FAQ agent -> táº¡o FAQ gá»‘c -> FAQ agent -> enrich -> embed -> indexing -> faq db
2) FAQ (gá»‘c) -> FAQ agent -> enrich -> embed -> indexing -> faq db

ðŸ†• Bá»• sung tiá»‡n Ã­ch/one-shot Ä‘á»ƒ dá»… tÃ­ch há»£p vá»›i DManager:
- ðŸ†• `coerce_from_augmented(...)` â€” chuyá»ƒn augmentedChunks (original/transformed) sang `AugmentedChunk`
- ðŸ†• `run_from_augmented(...)` â€” cháº¡y trá»n nhÃ¡nh (1) vÃ  index vÃ o Milvus qua `IndexingAgent`
- ðŸ†• `run_from_roots(...)` â€” cháº¡y trá»n nhÃ¡nh (2) vÃ  index
- ðŸ†• `index(...)` â€” tiá»‡n Ã­ch upsert vÃ o Milvus (dual collections) báº±ng `IndexingAgent`
- ðŸ†• `info()` â€” tráº£ thÃ´ng tin cáº¥u hÃ¬nh + embedder
- ðŸ”§ `make_index_payload(...)` â€” thÃªm tham sá»‘ `metric` (khÃ´ng cÃ²n hardcode "COSINE")
- ðŸ”§ `_mk_id(...)` â€” Ä‘á»•i sang id á»•n Ä‘á»‹nh báº±ng MD5 (trÃ¡nh phá»¥ thuá»™c PYTHONHASHSEED)
"""
from __future__ import annotations
from typing import Any, Dict, List, Optional, Protocol
from dataclasses import dataclass
from pydantic import BaseModel, Field, field_validator
import math
import json
import time
import hashlib  # ðŸ†• stable id

# ðŸ†• DÃ¹ng trá»±c tiáº¿p IndexingAgent Ä‘á»ƒ upsert
from indexing.indexing_agent import (
    IndexingAgent, AgentConfig, UpsertIndexReq, Item, IndexParams, Metric,
)

# ======================= Interfaces (Protocol) =======================

class IFaqGenerator(Protocol):
    """
    Generator interface ká»³ vá»ng:
    - generate_roots(chunks) -> List[Dict]: má»—i dict cÃ³ {question, answer, canonical_id, ...}
    - enrich_from_roots(roots, paraphrase_n=...) -> List[Dict]:
        tráº£ vá» list gá»“m cáº£ root + paraphrases (má»—i item cÃ³ question/answer; náº¿u lÃ  paraphrase nÃªn cÃ³ is_paraphrase=True)
    """
    def generate_roots(self, augmented_chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]: ...
    def enrich_from_roots(self, roots: List[Dict[str, Any]], paraphrase_n: int = 5) -> List[Dict[str, Any]]: ...


class IEmbedder(Protocol):
    """
    Embedder interface ká»³ vá»ng:
    - info() -> Dict[str, Any]  (tÃ¹y chá»n)
    - encode_texts(texts: List[str]) -> List[List[float]]  (float vectors, Ä‘Ã£ normalize hay chÆ°a tÃ¹y báº¡n)
    """
    def encode_texts(self, texts: List[str]) -> List[List[float]]: ...
    def info(self) -> Dict[str, Any]: ...


# ======================= Models =======================

class AugmentedChunk(BaseModel):
    doc_id: str
    chunk_id: str
    text: str
    metadata: Dict[str, Any] = Field(default_factory=dict)

    @field_validator("doc_id", "chunk_id", "text")
    @classmethod
    def _non_empty(cls, v: str) -> str:
        if not v or not v.strip():
            raise ValueError("field must be non-empty")
        return v


class FAQItem(BaseModel):
    question: str
    answer: str
    canonical_id: Optional[str] = None
    is_paraphrase: bool = False
    source: Optional[str] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)

    @field_validator("question", "answer")
    @classmethod
    def _non_empty(cls, v: str) -> str:
        if not v or not v.strip():
            raise ValueError("question/answer must be non-empty")
        return v


class FAQWithVec(FAQItem):
    vector: List[float]
    ts: int = 0  # Ä‘á»ƒ khá»›p schema indexing náº¿u báº¡n muá»‘n


# ======================= Config =======================

@dataclass
class FManagerConfig:
    # embed question hay answer? ThÃ´ng thÆ°á»ng embed QUESTION cho FAQ retrieval
    embed_field: str = "question"

    # default source to fill náº¿u thiáº¿u
    default_source: str = "faq_src"

    # cÃ³ L2-normalize vector khÃ´ng (há»¯u Ã­ch khi metric COSINE)
    l2_normalize: bool = True


# ======================= Manager =======================

class FManager:
    """
    Quáº£n lÃ½ luá»“ng FAQ:
    1) nháº­n augmented chunks (Ä‘Ã£ sinh tá»« Document pipeline)
    2) dÃ¹ng FAQ generator -> táº¡o FAQ gá»‘c (root), rá»“i enrich (paraphrase)
    3) embed cÃ¡c cÃ¢u há»i (hoáº·c theo config.embed_field)
    4) tráº£ vá» payload Ä‘Ã£ kÃ¨m vector, sáºµn sÃ ng gá»­i qua indexing_agent (op=index/upsert, type='faq')
    """

    def __init__(self, faq_generator: IFaqGenerator, embedder: IEmbedder, cfg: Optional[FManagerConfig] = None):
        self.gen = faq_generator
        self.embedder = embedder
        self.cfg = cfg or FManagerConfig()

    # --------- public API ---------

    def generate(self, chunks: List[AugmentedChunk], paraphrase_n: int = 5) -> Dict[str, List[FAQItem]]:
        """
        Táº¡o FAQ: root -> enrich. Chá»‰ build dá»¯ liá»‡u (chÆ°a embed).
        return: {"roots": [...], "faqs": [...]}
        """
        # Convert vá» dict Ä‘á»ƒ khÃ´ng phá»¥ thuá»™c model lá»›p ngoÃ i
        chunk_dicts = [c.model_dump() for c in chunks]

        roots_raw = self.gen.generate_roots(chunk_dicts)
        roots = [self._coerce_faq_item(r, is_paraphrase=False) for r in roots_raw]

        enriched_raw = self.gen.enrich_from_roots([r.model_dump() for r in roots], paraphrase_n=paraphrase_n)
        faqs = [self._coerce_faq_item(e) for e in enriched_raw]

        return {"roots": roots, "faqs": faqs}

    def embed(self, faqs: List[FAQItem]) -> List[FAQWithVec]:
        """
        Embed danh sÃ¡ch FAQ theo config.embed_field (máº·c Ä‘á»‹nh lÃ  question).
        """
        if not faqs:
            return []
        texts = [(f.question if self.cfg.embed_field == "question" else f.answer) for f in faqs]
        vecs = self.embedder.encode_texts(texts)

        if self.cfg.l2_normalize:
            for v in vecs:
                self._l2_normalize_inplace(v)

        ts_now = int(time.time())
        out: List[FAQWithVec] = []
        for f, v in zip(faqs, vecs):
            out.append(FAQWithVec(
                question=f.question,
                answer=f.answer,
                canonical_id=f.canonical_id,
                is_paraphrase=f.is_paraphrase,
                source=f.source or self.cfg.default_source,
                metadata=f.metadata or {},
                vector=v,
                ts=ts_now
            ))
        return out

    # ðŸ”§ thÃªm tham sá»‘ metric (trÆ°á»›c Ä‘Ã¢y hardcode COSINE)
    def make_index_payload(self, collection_base: str, items_with_vec: List[FAQWithVec], *, metric: Metric = "COSINE") -> Dict[str, Any]:
        """
        Táº¡o payload (dict) tÆ°Æ¡ng thÃ­ch IndexingAgent.upsert (dual-collection mode).
        LÆ°u Ã½: IndexingAgent sáº½ tÃ¡ch sang __faq dá»±a trÃªn field 'type' = 'faq'.
        """
        return {
            "op": "upsert",
            "collection": collection_base,
            "metric_type": metric,
            "items": [
                {
                    "id": self._mk_id(it),
                    "type": "faq",
                    "vector": it.vector,
                    "question": it.question,
                    "answer": it.answer,
                    "source": it.source or self.cfg.default_source,
                    "metadata": {
                        **(it.metadata or {}),
                        "canonical_id": it.canonical_id or "",
                        "is_paraphrase": it.is_paraphrase
                    },
                    "ts": it.ts,
                }
                for it in items_with_vec
            ]
        }

    # ðŸ†• Adapter: nháº­n augmentedChunks tá»« D manager (original/transformed)
    def coerce_from_augmented(self, augmented: List[Dict[str, Any]]) -> List[AugmentedChunk]:
        out: List[AugmentedChunk] = []
        for row in augmented:
            text = str(row.get("transformed") or row.get("original") or row.get("text") or "").strip()
            if not text:
                continue
            doc_id = str(row.get("doc_id") or "").strip() or "doc"
            chunk_id = str(row.get("chunk_id") or "").strip() or str(len(out))
            meta = row.get("metadata") or {}
            if not isinstance(meta, dict):
                meta = {"raw_meta": meta}
            out.append(AugmentedChunk(doc_id=doc_id, chunk_id=chunk_id, text=text, metadata=meta))
        return out

    # ðŸ†• One-shot: NhÃ¡nh (1) â€” tá»« augmentedChunks tá»›i index
    def run_from_augmented(
        self,
        augmented: List[Dict[str, Any]],
        *,
        collection_base: str,
        paraphrase_n: int = 5,
        metric: Metric = "COSINE",
        index_params: Optional[IndexParams] = None,
        shards: int = 2,
        build_index: bool = True,
    ) -> Dict[str, Any]:
        chunks = self.coerce_from_augmented(augmented)
        built = self.generate(chunks, paraphrase_n=paraphrase_n)
        vec_items = self.embed(built["faqs"])  # embed all enriched (gá»“m cáº£ roots náº¿u generator tráº£ vá»)
        payload = self.make_index_payload(collection_base, vec_items, metric=metric)
        # Upsert báº±ng IndexingAgent
        ia = IndexingAgent(AgentConfig())
        req = UpsertIndexReq(
            op="upsert", collection=collection_base, dim=len(vec_items[0].vector) if vec_items else None,
            metric_type=metric, items=[Item(**it) if not isinstance(it, Item) else it for it in payload["items"]],
            shards_num=shards, index_params=index_params, build_index=build_index,
        )
        resp = ia.process(req.model_dump())
        return {
            "summary": {
                "chunks_in": len(chunks),
                "roots": len(built["roots"]),
                "faqs": len(built["faqs"]),
                "embedded": len(vec_items),
            },
            "resp": resp,
        }

    # ðŸ†• One-shot: NhÃ¡nh (2) â€” tá»« FAQ gá»‘c tá»›i index
    def run_from_roots(
        self,
        roots: List[Dict[str, Any]],
        *,
        collection_base: str,
        paraphrase_n: int = 5,
        metric: Metric = "COSINE",
        index_params: Optional[IndexParams] = None,
        shards: int = 2,
        build_index: bool = True,
    ) -> Dict[str, Any]:
        enriched_raw = self.gen.enrich_from_roots(roots, paraphrase_n=paraphrase_n)
        faqs = [self._coerce_faq_item(e) for e in enriched_raw]
        vec_items = self.embed(faqs)
        payload = self.make_index_payload(collection_base, vec_items, metric=metric)
        ia = IndexingAgent(AgentConfig())
        req = UpsertIndexReq(
            op="upsert", collection=collection_base, dim=len(vec_items[0].vector) if vec_items else None,
            metric_type=metric, items=[Item(**it) if not isinstance(it, Item) else it for it in payload["items"]],
            shards_num=shards, index_params=index_params, build_index=build_index,
        )
        resp = ia.process(req.model_dump())
        return {
            "summary": {
                "roots_in": len(roots),
                "faqs": len(faqs),
                "embedded": len(vec_items),
            },
            "resp": resp,
        }

    # ðŸ†• Tiá»‡n Ã­ch index trá»±c tiáº¿p (Ä‘Ã£ cÃ³ vector)
    def index(
        self,
        items_with_vec: List[FAQWithVec],
        *,
        collection_base: str,
        metric: Metric = "COSINE",
        index_params: Optional[IndexParams] = None,
        shards: int = 2,
        build_index: bool = True,
    ) -> Dict[str, Any]:
        payload = self.make_index_payload(collection_base, items_with_vec, metric=metric)
        ia = IndexingAgent(AgentConfig())
        req = UpsertIndexReq(
            op="upsert", collection=collection_base, dim=len(items_with_vec[0].vector) if items_with_vec else None,
            metric_type=metric, items=[Item(**it) if not isinstance(it, Item) else it for it in payload["items"]],
            shards_num=shards, index_params=index_params, build_index=build_index,
        )
        return ia.process(req.model_dump())

    # ðŸ†• Expose thÃ´ng tin cáº¥u hÃ¬nh & embedder
    def info(self) -> Dict[str, Any]:
        return {
            "cfg": {
                "embed_field": self.cfg.embed_field,
                "default_source": self.cfg.default_source,
                "l2_normalize": self.cfg.l2_normalize,
            },
            "embedder": (self.embedder.info() if hasattr(self.embedder, "info") else {}),
        }

    # --------- helpers ---------

    def _coerce_faq_item(self, r: Dict[str, Any], is_paraphrase: Optional[bool] = None) -> FAQItem:
        q = str(r.get("question", "")).strip()
        a = str(r.get("answer", "")).strip()
        can = r.get("canonical_id")
        src = r.get("source")
        meta = r.get("metadata") or {}

        ip = bool(r.get("is_paraphrase")) if is_paraphrase is None else bool(is_paraphrase)

        return FAQItem(
            question=q,
            answer=a,
            canonical_id=(str(can) if can else None),
            is_paraphrase=ip,
            source=(str(src) if src else None),
            metadata=(meta if isinstance(meta, dict) else {})
        )

    def _l2_normalize_inplace(self, v: List[float]) -> None:
        s = 0.0
        for x in v:
            s += x * x
        if s <= 0:
            return
        inv = 1.0 / math.sqrt(s)
        for i in range(len(v)):
            v[i] *= inv

    # ðŸ”§ dÃ¹ng MD5 Ä‘á»ƒ cÃ³ id á»•n Ä‘á»‹nh (deterministic)
    def _mk_id(self, it: FAQWithVec) -> str:
        base = f"{(it.canonical_id or 'c')[:32]}|{int(it.is_paraphrase)}|{(it.question or '')[:256]}"
        return hashlib.md5(base.encode("utf-8")).hexdigest()
