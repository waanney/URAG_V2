# -*- coding: utf-8 -*-
"""
FManager ‚Äî FAQ pipeline orchestrator
===================================

Ch·ª©c nƒÉng ƒë√∫ng theo y√™u c·∫ßu:
1) augmentedChunks t√†i li·ªáu -> FAQ agent -> t·∫°o FAQ g·ªëc -> FAQ agent -> enrich -> embed -> indexing -> faq db
2) FAQ (g·ªëc) -> FAQ agent -> enrich -> embed -> indexing -> faq db

üÜï B·ªï sung ti·ªán √≠ch/one-shot ƒë·ªÉ d·ªÖ t√≠ch h·ª£p v·ªõi DManager:
- üÜï `coerce_from_augmented(...)` ‚Äî chuy·ªÉn augmentedChunks (original/transformed) sang `AugmentedChunk`
- üÜï `run_from_augmented(...)` ‚Äî ch·∫°y tr·ªçn nh√°nh (1) v√† index v√†o Milvus qua `IndexingAgent`
- üÜï `run_from_roots(...)` ‚Äî ch·∫°y tr·ªçn nh√°nh (2) v√† index
- üÜï `index(...)` ‚Äî ti·ªán √≠ch upsert v√†o Milvus (dual collections) b·∫±ng `IndexingAgent`
- üÜï `info()` ‚Äî tr·∫£ th√¥ng tin c·∫•u h√¨nh + embedder
- üîß `make_index_payload(...)` ‚Äî th√™m tham s·ªë `metric` (kh√¥ng c√≤n hardcode "COSINE")
- üîß `_mk_id(...)` ‚Äî ƒë·ªïi sang id ·ªïn ƒë·ªãnh b·∫±ng MD5 (tr√°nh ph·ª• thu·ªôc PYTHONHASHSEED)
"""
from __future__ import annotations
from typing import Any, Dict, List, Optional, Protocol
from dataclasses import dataclass
from pydantic import BaseModel, Field, field_validator
import math
import json
import time
import hashlib  # üÜï stable id

# üÜï D√πng tr·ª±c ti·∫øp IndexingAgent ƒë·ªÉ upsert
from indexing.indexing_agent import (
    IndexingAgent, AgentConfig, UpsertIndexReq, Item, IndexParams, Metric,
)

# ======================= Interfaces (Protocol) =======================

class IFaqGenerator(Protocol):
    """
    Generator interface k·ª≥ v·ªçng:
    - generate_roots(chunks) -> List[Dict]: m·ªói dict c√≥ {question, answer, canonical_id, ...}
    - enrich_from_roots(roots, paraphrase_n=...) -> List[Dict]:
        tr·∫£ v·ªÅ list g·ªìm c·∫£ root + paraphrases (m·ªói item c√≥ question/answer; n·∫øu l√† paraphrase n√™n c√≥ is_paraphrase=True)
    """
    def generate_roots(self, augmented_chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]: ...
    def enrich_from_roots(self, roots: List[Dict[str, Any]], paraphrase_n: int = 5) -> List[Dict[str, Any]]: ...


class IEmbedder(Protocol):
    """
    Embedder interface k·ª≥ v·ªçng:
    - info() -> Dict[str, Any]  (t√πy ch·ªçn)
    - encode_texts(texts: List[str]) -> List[List[float]]  (float vectors, ƒë√£ normalize hay ch∆∞a t√πy b·∫°n)
    """
    def encode_texts(self, texts: List[str]) -> List[List[float]]: ...
    def info(self) -> Dict[str, Any]: ...


# ======================= Models =======================

class AugmentedChunk(BaseModel):
    doc_id: str
    chunk_id: str
    text: str
    metadata: Dict[str, Any] = Field(default_factory=dict)

    @field_validator("doc_id", "chunk_id", "text")
    @classmethod
    def _non_empty(cls, v: str) -> str:
        if not v or not v.strip():
            raise ValueError("field must be non-empty")
        return v


class FAQItem(BaseModel):
    question: str
    answer: str
    canonical_id: Optional[str] = None
    is_paraphrase: bool = False
    source: Optional[str] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)

    @field_validator("question", "answer")
    @classmethod
    def _non_empty(cls, v: str) -> str:
        if not v or not v.strip():
            raise ValueError("question/answer must be non-empty")
        return v


class FAQWithVec(FAQItem):
    vector: List[float]
    ts: int = 0  # ƒë·ªÉ kh·ªõp schema indexing n·∫øu b·∫°n mu·ªën


# ======================= Config =======================

@dataclass
class FManagerConfig:
    # embed question hay answer? Th√¥ng th∆∞·ªùng embed QUESTION cho FAQ retrieval
    embed_field: str = "question"

    # default source to fill n·∫øu thi·∫øu
    default_source: str = "faq_src"

    # c√≥ L2-normalize vector kh√¥ng (h·ªØu √≠ch khi metric COSINE)
    l2_normalize: bool = True


# ======================= Manager =======================

class FManager:
    """
    Qu·∫£n l√Ω lu·ªìng FAQ:
    1) nh·∫≠n augmented chunks (ƒë√£ sinh t·ª´ Document pipeline)
    2) d√πng FAQ generator -> t·∫°o FAQ g·ªëc (root), r·ªìi enrich (paraphrase)
    3) embed c√°c c√¢u h·ªèi (ho·∫∑c theo config.embed_field)
    4) tr·∫£ v·ªÅ payload ƒë√£ k√®m vector, s·∫µn s√†ng g·ª≠i qua indexing_agent (op=index/upsert, type='faq')
    """

    def __init__(self, faq_generator: IFaqGenerator, embedder: IEmbedder, cfg: Optional[FManagerConfig] = None):
        self.gen = faq_generator
        self.embedder = embedder
        self.cfg = cfg or FManagerConfig()

    # --------- public API ---------

    def generate(self, chunks: List[AugmentedChunk], paraphrase_n: int = 5) -> Dict[str, List[FAQItem]]:
        """
        T·∫°o FAQ: root -> enrich. Ch·ªâ build d·ªØ li·ªáu (ch∆∞a embed).
        return: {"roots": [...], "faqs": [...]}
        """
        # Convert v·ªÅ dict ƒë·ªÉ kh√¥ng ph·ª• thu·ªôc model l·ªõp ngo√†i
        chunk_dicts = [c.model_dump() for c in chunks]

        roots_raw = self.gen.generate_roots(chunk_dicts)
        roots = [self._coerce_faq_item(r, is_paraphrase=False) for r in roots_raw]

        enriched_raw = self.gen.enrich_from_roots([r.model_dump() for r in roots], paraphrase_n=paraphrase_n)
        faqs = [self._coerce_faq_item(e) for e in enriched_raw]

        return {"roots": roots, "faqs": faqs}

    def embed(self, faqs: List[FAQItem]) -> List[FAQWithVec]:
        """
        Embed danh s√°ch FAQ theo config.embed_field (m·∫∑c ƒë·ªãnh l√† question).
        """
        if not faqs:
            return []
        texts = [(f.question if self.cfg.embed_field == "question" else f.answer) for f in faqs]
        vecs = self.embedder.encode_texts(texts)

        if self.cfg.l2_normalize:
            for v in vecs:
                self._l2_normalize_inplace(v)

        ts_now = int(time.time())
        out: List[FAQWithVec] = []
        for f, v in zip(faqs, vecs):
            out.append(FAQWithVec(
                question=f.question,
                answer=f.answer,
                canonical_id=f.canonical_id,
                is_paraphrase=f.is_paraphrase,
                source=f.source or self.cfg.default_source,
                metadata=f.metadata or {},
                vector=v,
                ts=ts_now
            ))
        return out

    # üîß th√™m tham s·ªë metric (tr∆∞·ªõc ƒë√¢y hardcode COSINE)
    def make_index_payload(self, collection_base: str, items_with_vec: List[FAQWithVec], *, metric: Metric = "COSINE") -> Dict[str, Any]:
        """
        T·∫°o payload (dict) t∆∞∆°ng th√≠ch IndexingAgent.upsert (dual-collection mode).
        L∆∞u √Ω: IndexingAgent s·∫Ω t√°ch sang __faq d·ª±a tr√™n field 'type' = 'faq'.
        """
        return {
            "op": "upsert",
            "collection": collection_base,
            "metric_type": metric,
            "items": [
                {
                    "id": self._mk_id(it),
                    "type": "faq",
                    "vector": it.vector,
                    "question": it.question,
                    "answer": it.answer,
                    "source": it.source or self.cfg.default_source,
                    "metadata": {
                        **(it.metadata or {}),
                        "canonical_id": it.canonical_id or "",
                        "is_paraphrase": it.is_paraphrase
                    },
                    "ts": it.ts,
                }
                for it in items_with_vec
            ]
        }

    # üÜï Adapter: nh·∫≠n augmentedChunks t·ª´ D manager (original/transformed)
    def coerce_from_augmented(self, augmented: List[Dict[str, Any]]) -> List[AugmentedChunk]:
        out: List[AugmentedChunk] = []
        for row in augmented:
            text = str(row.get("transformed") or row.get("original") or row.get("text") or "").strip()
            if not text:
                continue
            doc_id = str(row.get("doc_id") or "").strip() or "doc"
            chunk_id = str(row.get("chunk_id") or "").strip() or str(len(out))
            meta = row.get("metadata") or {}
            if not isinstance(meta, dict):
                meta = {"raw_meta": meta}
            out.append(AugmentedChunk(doc_id=doc_id, chunk_id=chunk_id, text=text, metadata=meta))
        return out

    # üÜï One-shot: Nh√°nh (1) ‚Äî t·ª´ augmentedChunks t·ªõi index
    def run_from_augmented(
        self,
        augmented: List[Dict[str, Any]],
        *,
        collection_base: str,
        paraphrase_n: int = 5,
        metric: Metric = "COSINE",
        index_params: Optional[IndexParams] = None,
        shards: int = 2,
        build_index: bool = True,
    ) -> Dict[str, Any]:
        chunks = self.coerce_from_augmented(augmented)
        built = self.generate(chunks, paraphrase_n=paraphrase_n)
        vec_items = self.embed(built["faqs"])  # embed all enriched (g·ªìm c·∫£ roots n·∫øu generator tr·∫£ v·ªÅ)
        payload = self.make_index_payload(collection_base, vec_items, metric=metric)
        # Upsert b·∫±ng IndexingAgent
        ia = IndexingAgent(AgentConfig())
        req = UpsertIndexReq(
            op="upsert", collection=collection_base, dim=len(vec_items[0].vector) if vec_items else None,
            metric_type=metric, items=[Item(**it) if not isinstance(it, Item) else it for it in payload["items"]],
            shards_num=shards, index_params=index_params, build_index=build_index,
        )
        resp = ia.process(req.model_dump())
        return {
            "summary": {
                "chunks_in": len(chunks),
                "roots": len(built["roots"]),
                "faqs": len(built["faqs"]),
                "embedded": len(vec_items),
            },
            "resp": resp,
        }

    # üÜï One-shot: Nh√°nh (2) ‚Äî t·ª´ FAQ g·ªëc t·ªõi index
    def run_from_roots(
        self,
        roots: List[Dict[str, Any]],
        *,
        collection_base: str,
        paraphrase_n: int = 5,
        metric: Metric = "COSINE",
        index_params: Optional[IndexParams] = None,
        shards: int = 2,
        build_index: bool = True,
    ) -> Dict[str, Any]:
        enriched_raw = self.gen.enrich_from_roots(roots, paraphrase_n=paraphrase_n)
        faqs = [self._coerce_faq_item(e) for e in enriched_raw]
        vec_items = self.embed(faqs)
        payload = self.make_index_payload(collection_base, vec_items, metric=metric)
        ia = IndexingAgent(AgentConfig())
        req = UpsertIndexReq(
            op="upsert", collection=collection_base, dim=len(vec_items[0].vector) if vec_items else None,
            metric_type=metric, items=[Item(**it) if not isinstance(it, Item) else it for it in payload["items"]],
            shards_num=shards, index_params=index_params, build_index=build_index,
        )
        resp = ia.process(req.model_dump())
        return {
            "summary": {
                "roots_in": len(roots),
                "faqs": len(faqs),
                "embedded": len(vec_items),
            },
            "resp": resp,
        }

    # üÜï Ti·ªán √≠ch index tr·ª±c ti·∫øp (ƒë√£ c√≥ vector)
    def index(
        self,
        items_with_vec: List[FAQWithVec],
        *,
        collection_base: str,
        metric: Metric = "COSINE",
        index_params: Optional[IndexParams] = None,
        shards: int = 2,
        build_index: bool = True,
    ) -> Dict[str, Any]:
        payload = self.make_index_payload(collection_base, items_with_vec, metric=metric)
        ia = IndexingAgent(AgentConfig())
        req = UpsertIndexReq(
            op="upsert", collection=collection_base, dim=len(items_with_vec[0].vector) if items_with_vec else None,
            metric_type=metric, items=[Item(**it) if not isinstance(it, Item) else it for it in payload["items"]],
            shards_num=shards, index_params=index_params, build_index=build_index,
        )
        return ia.process(req.model_dump())

    # üÜï Expose th√¥ng tin c·∫•u h√¨nh & embedder
    def info(self) -> Dict[str, Any]:
        return {
            "cfg": {
                "embed_field": self.cfg.embed_field,
                "default_source": self.cfg.default_source,
                "l2_normalize": self.cfg.l2_normalize,
            },
            "embedder": (self.embedder.info() if hasattr(self.embedder, "info") else {}),
        }

    # --------- helpers ---------

    def _coerce_faq_item(self, r: Dict[str, Any], is_paraphrase: Optional[bool] = None) -> FAQItem:
        q = str(r.get("question", "")).strip()
        a = str(r.get("answer", "")).strip()
        can = r.get("canonical_id")
        src = r.get("source")
        meta = r.get("metadata") or {}

        ip = bool(r.get("is_paraphrase")) if is_paraphrase is None else bool(is_paraphrase)

        return FAQItem(
            question=q,
            answer=a,
            canonical_id=(str(can) if can else None),
            is_paraphrase=ip,
            source=(str(src) if src else None),
            metadata=(meta if isinstance(meta, dict) else {})
        )

    def _l2_normalize_inplace(self, v: List[float]) -> None:
        s = 0.0
        for x in v:
            s += x * x
        if s <= 0:
            return
        inv = 1.0 / math.sqrt(s)
        for i in range(len(v)):
            v[i] *= inv

    # üîß d√πng MD5 ƒë·ªÉ c√≥ id ·ªïn ƒë·ªãnh (deterministic)
    def _mk_id(self, it: FAQWithVec) -> str:
        base = f"{(it.canonical_id or 'c')[:32]}|{int(it.is_paraphrase)}|{(it.question or '')[:256]}"
        return hashlib.md5(base.encode("utf-8")).hexdigest()
